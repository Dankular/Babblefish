# BabbleFish TTS Server Configuration

# ========== Device Configuration ==========
# Use "cuda" for GPU, "cpu" for CPU only
DEVICE=cuda

# Compute type for quantization
# Options: int8 (optimal for 4GB VRAM), int16, float16, float32
COMPUTE_TYPE=int8

# ========== Server Configuration ==========
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# ========== Model Paths ==========
MODELS_DIR=models
WHISPER_MODEL_SIZE=medium
NLLB_MODEL_PATH=models/nllb-200-distilled-600M-ct2

# ========== ASR Settings (faster-whisper) ==========
WHISPER_BEAM_SIZE=5
WHISPER_VAD_FILTER=true

# ========== Translation Settings (NLLB-200) ==========
NLLB_BEAM_SIZE=4

# ========== Audio Settings ==========
SAMPLE_RATE=16000
AUDIO_CHUNK_SIZE=4096
